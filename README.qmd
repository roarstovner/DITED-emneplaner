---
title: "Rapport om f칮rpilot for emneplandelen av TEPS"
author: "Roar Bakken Stovner"
date: 2024-12-11
format: md
---

```{r}
#| output: FALSE
#| warning: FALSE

library(tidyverse)
```

## Rapport om TEPS Emneplaner, f칮rpilot

Jeg har gjort s친 mye som mulig p친 15 timer og endte med 친 bruke 16. Jeg rakk 친

1.  automatisk laste ned .html ut fra en liste med URLer
2.  automatisk hente ut data fra enkelte tags i htmlen
3.  fjerne html-tags og kun st친 igjen med emneplanen
4.  kode fire variable med gpt
5.  gjort en manuell sammenlikning med de menneskelige koderne.

Jeg benyttet ca. 8 timer p친 del 1-3 og ca. 6 timer p친 4-5 og ca. 2 timer p친 denne rapporten. Det tar n친 ca. 1 time 친 kode en ny variabel og rekode den i henhold til kodeboka, men det kommer til 친 ta lenger tid n친r alt skal valideres bedre.

Jeg betalte $1,17 for beregningstid hos OpenAI. Jeg ansl친r at det koster 3 kr 친 kode hvert emne p친 alle variablene hvis vi henter 10 variable fra html-tags. Hvis det da er 50 kurs p친 18 studiesteder blir total kostnad 2700 kr per 친r.

## Tags fra .html

Dataen jeg fikk fra .html ser slik ut. Jeg viser bare for ett fag.

```{r}
emneplaner <- read_rds("data/emneplaner.Rds")
emneplaner |> slice(1) |> glimpse()
```

Dataene vi kan h칮ste rett fra html-fila kommer til 친 variere fra institutsjon til institusjon, men trolig kan vi h칮ste mange av variablene rett fra html-tags uten 친 benytte en spr친kmodell.

Emneplanen vi henter ut blir seende slik ut:

```{r}
emneplaner$fulltekst[1]
```

Dette er flott for en maskin, for tegnene "\\n" betyr newline, s친 en maskin vil lese dette som en lang tekst med fin avsnittstruktur.

# Kode variable med GPT

Jeg har kodet fire variable. Jeg valgte variable ut fra kriteriet "stigende kompleksitet". Variablene er "forkunnskap" (ja/nei), "eksamensform" (8 forskjellige ja/nei), "arbeidskrav" (7 forskjellige ja nei) og "arbeidskravantall" (et heltall).

## Forkunnskap

Her er dataene for den menneskelige kodingen av 'forkunnskapskrav' pluss tre kall til spr친kmodellen.

```{r}
forkunnskap <- read_rds("data/forkunnskap.Rds") |> arrange(emnekode)
begrunnelse <- forkunnskap |> filter(!is.na(begrunnelse)) |> select(emnekode,begrunnelse)

forkunnskap |> select(!begrunnelse) |> pivot_wider(names_from = koder, values_from = Forkunnskapskrav) |> select(-human3) |> left_join(begrunnelse, by = "emnekode") |> tinytable::tt()
```

Kolonnenavnet angir spr친kmodellen, henholdsvis den billigere og raskere gpt-4o-mini og gpt-4o. Den varianter med gpt-4o som slutter p친 "CoT" benytter *Chain of thought reasoning* (CoT). Dette er at man f칮rst ber modellen om 친 resonnere og begrunne og deretter ber om svar. Begrunnelsen er i en egen kolonne. Vi ser at modellen synes det er uklart om "Ingen" og "Ingen forkunnskapskrav" er 친 eksplisitt nevne forkunnskapskrav eller ikke. Vi b칮r i fremtiden endre svaralternativene til

1.  Ingen forkunnskapskrav
2.  Ingen forkunnskapskrav nevnt.
3.  Forkunnskapskrav nevnt.

Bortsett fra dette ser det ut til at spr친kmodellene finner forkunnskapskravene og med riktig begrunnelse.

## Eksamensform

Her er dataene for eksamensform. Siden det er s친 mange variabler m친 man lese denne tabellen annerledes. Hver fjerde rad er ett emne.

```{r}
eksamensform <- read_rds("data/eksamensform.Rds")

eksamensform |> select(-gpt_model,-gpt_response) |> relocate(koder, .after = emnekode) |> tinytable::tt()
```

Hvis man ser p친 den dyre modellen, "gpt-4o", er det knapt mulig 친 spore uenighet med menneskene, men noen er det:

-   MGKH2100 (kunst og h친ndverk), spr친kmodellen finner en mappeeksamen som menneskene ikke finner. Ett menneske ser et refleksjonsnotat som ingen andre finner. MGKH2100 har muntlig eksamen der studentene skal levere et refleksjonsnotat p친 forh친nd. Det er ogs친 en mappeinnlevering som en obligatorisk del av kurset. Kun det ene mennesket kodet riktig.\
-   MGMO5900 (masteremnet), spr친kmodellen koder at de entrepren칮riellene masterne har muntlig forsvar av graden, men menneskene sier kun skriftlig eksamen. Spr친kmodellen har rett, men dette kan diskuteres.
-   MGNO4200 (norsk), spr친kmodellen finner en muntlig eksamen, mens mennesket finner ingen. Spr친kmodellen har rett.

Spr친kmodellen kodet alts친 jevngodt eller s친vidt bedre enn menneskene.

## Arbeidskrav

N친 har jeg funnet ut at "gpt-4o-mini" bare er for d친rlig, s친 jeg viser ikke den i disse dataene.

Jeg fant ut at den beste m친ten 친 kode dette p친 var 친 ikke ha "ja/nei" p친 hver enkelt arbeidskravstype, men kode antallet av hver type arbeidskrav. Da kunne man summere opp totalt antall arbeidskrav p친 slutten, og man trenger ikke 친 basere seg p친 at spr친kmodellen kan telle, noe de er d친rlige til.

```{r}
arbeidskrav <- read_rds("data/arbeidskrav.Rds")

arbeidskrav |> filter(koder != "gpt-4o-mini-2024-07-18") |> select(-gpt_response) |> tinytable::tt()
```

Dette er det komplette kaos, men det er fordi det er vanskelig 친 bed칮mme hva som er et arbeidskrav. Det er i hvert fall opplagt at menneskene ogs친 er uenige seg imellom.

Jeg ba spr친kmodellen om 친 nevne hva den telte som arbeidskrav:

```{r}
arbeidskrav |> filter(koder != "gpt-4o-mini-2024-07-18") |> select(emnekode, koder, Arbeidskravantall, gpt_response) |> tinytable::tt()
```

Jeg har etterg친tt noen av de arbeidskravene som spr친kmodellen nevner, og alle jeg har sjekket st친r i emneplanen.

For meg virker det som om vi m친 definere arbeidskrav bedre. Av og til teller de menneskelige koderne obligatorisk oppm칮te som et arbeidskrav, men av og til ikke. I prompten ba jeg spr친kmodellen om 친 ikke telle eksamener og obligatorisk oppm칮te som arbeidskrav, men det ser ut til at den teller obligatorisk oppm칮te av og til. Og det gj칮r jommen menneskene ogs친. 游뗶

# Konklusjoner

Konklusjonene er vel som TEPS-prosjektet om mastergrader: menneskene og spr친kmodellene koder ulikt, men det skyldes uklare koder. Jeg tror at ved 친 klargj칮re kodeskjemaet sammen med spr친kmodellene vil alle disse variablene kunne kodes forholdsvis likt. Et lite sp칮rsm친lstegn bak antall arbeidskrav, men dette skyldes ikke at spr친kmodellene er d친rlige til 친 gj칮re opptellingen, snarere at det er vanskelig 친 definere hva som er et arbeidskrav.
